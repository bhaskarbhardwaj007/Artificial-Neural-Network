{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Copy of B1.4.2 - ANN, students' sheet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9LIaZ0Lt0ad"
      },
      "source": [
        "## Artificial Neural Network\n",
        "Context: this dataset is created for prediction of Graduate Admissions from an Indian perspective.\n",
        "Content: the dataset contains several parameters which are considered important during the application for Masters Programs. The parameters included are : 1. GRE Scores ( out of 340 ) 2. TOEFL Scores ( out of 120 ) 3. University Rating ( out of 5 ) 4. Statement of Purpose and Letter of Recommendation Strength ( out of 5 ) 5. Undergraduate GPA ( out of 10 ) 6. Research Experience ( either 0 or 1 ) 7. Chance of Admit ( ranging from 0 to 1 )\n",
        "\n",
        "Reference: Mohan S Acharya, Asfia Armaan, Aneeta S Antony : A Comparison of Regression Models for Prediction of Graduate Admissions, IEEE International Conference on Computational Intelligence in Data Science 2019"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZPkK_xyt0ag"
      },
      "source": [
        "# Import Librairies\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kc0rmeq31Gq"
      },
      "source": [
        "### 1) Download the dataset from this link https://www.kaggle.com/mohansacharya/graduate-admissions and put the csv file in the same directory as the current notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uuIMWYJt0ak",
        "outputId": "72288054-0a39-480b-d2fd-e4dfea66d6d9",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "import io\n",
        "dataset = pd.read_csv(io.BytesIO(uploaded['Admission_Predict_Ver1.1.csv']))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-92dd6e35-fffe-4311-90d3-e662df17b508\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-92dd6e35-fffe-4311-90d3-e662df17b508\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Admission_Predict_Ver1.1.csv to Admission_Predict_Ver1.1.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1889sUG35O9"
      },
      "source": [
        "### 2) Analyze the data\n",
        "Print the first columns of the data set using pandas. Get a report using Pandas Profiling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gliFsf1Yt0ao",
        "outputId": "2ef426c3-bd64-4be0-ac77-d789b3fbde92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Serial No.</th>\n",
              "      <th>GRE Score</th>\n",
              "      <th>TOEFL Score</th>\n",
              "      <th>University Rating</th>\n",
              "      <th>SOP</th>\n",
              "      <th>LOR</th>\n",
              "      <th>CGPA</th>\n",
              "      <th>Research</th>\n",
              "      <th>Chance of Admit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>337</td>\n",
              "      <td>118</td>\n",
              "      <td>4</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>9.65</td>\n",
              "      <td>1</td>\n",
              "      <td>0.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>324</td>\n",
              "      <td>107</td>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>8.87</td>\n",
              "      <td>1</td>\n",
              "      <td>0.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>316</td>\n",
              "      <td>104</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>8.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>322</td>\n",
              "      <td>110</td>\n",
              "      <td>3</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>8.67</td>\n",
              "      <td>1</td>\n",
              "      <td>0.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>314</td>\n",
              "      <td>103</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.21</td>\n",
              "      <td>0</td>\n",
              "      <td>0.65</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Serial No.  GRE Score  TOEFL Score  ...  CGPA  Research  Chance of Admit \n",
              "0           1        337          118  ...  9.65         1              0.92\n",
              "1           2        324          107  ...  8.87         1              0.76\n",
              "2           3        316          104  ...  8.00         1              0.72\n",
              "3           4        322          110  ...  8.67         1              0.80\n",
              "4           5        314          103  ...  8.21         0              0.65\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PV_b8obMcbat",
        "outputId": "4d96e774-5039-4bdc-e3c8-875aa449f794",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "source": [
        "import pandas as pd\n",
        "from pandas_profiling import ProfileReport\n",
        "profile = ProfileReport(dataset)   #good one\n",
        "profile.to_file(\"report.html\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-c0b4c477eb32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProfileReport\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprofile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProfileReport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m#good one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprofile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"report.html\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas_profiling/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, df, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sample'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mdescription_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         self.html = to_html(sample,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas_profiling/describe.py\u001b[0m in \u001b[0;36mdescribe\u001b[0;34m(df, bins, check_correlation, correlation_threshold, correlation_overrides, check_recoded, pool_size, **kwargs)\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m     \u001b[0mvariable_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mldesc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin_axes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m     \u001b[0mvariable_stats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: concat() got an unexpected keyword argument 'join_axes'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHr-MMj64CS0"
      },
      "source": [
        "###3) Building X and y data\n",
        "We call `X` the input composed of the following columns of the dataset: [\"GRE Score\", \"TOEFL Score\", \"University Rating\", \"SOP\", \"LOR \", \"CGPA\", \"Research\"] and `y` the output (target) composed of one column [\"Chance of Admit \"].\n",
        "<b>Build X and y.</b><br>\n",
        "\n",
        "**Hint:**\n",
        "df[['A', 'Z']] : returns all the rows and only column A and Z.<br>\n",
        "(You can also try slicing, for example df.iloc[:, 2:4])</i>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sBQ_QLQt0aq"
      },
      "source": [
        "X = dataset[[\"GRE Score\", \"TOEFL Score\", \"University Rating\", \"SOP\", \"LOR \", \"CGPA\", \"Research\"]]\n",
        "y = dataset[[\"Chance of Admit \"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AL66_scW4LYn"
      },
      "source": [
        " X and y are DataFrames, to be used by numpy we have to transform them into arrays: transform X and y into arrays using \".values\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asNgvIBVt0at"
      },
      "source": [
        "X = X.values\n",
        "y = y.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3v0RxhAq4RBX"
      },
      "source": [
        "### 4) Test-train split\n",
        "Split data into training and testing datas, the training data is used to train the model, and the testing data is used to test: use the sklearn functionnality : https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "az5y3f-It0aw"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cv6Tv1OU4XGz"
      },
      "source": [
        "Using the \"print\" function, display all the splitted data: X_train, X_test, y_train, y_test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7K0qXdDpdMl-",
        "outputId": "ff1a4cd0-f119-4202-cfdc-27095ffcbdd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "print(\"X_train\",X_train)\n",
        "print(\"X_test\",X_test)\n",
        "print(\"y_train\",y_train.T)\n",
        "print(\"y_test\",y_test.T)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train [[321.   111.     3.   ...   4.     8.83   1.  ]\n",
            " [316.   111.     4.   ...   5.     8.54   0.  ]\n",
            " [303.   102.     3.   ...   3.     8.5    0.  ]\n",
            " ...\n",
            " [302.    99.     1.   ...   2.     7.25   0.  ]\n",
            " [309.   105.     2.   ...   4.     7.68   0.  ]\n",
            " [314.   106.     2.   ...   3.5    8.25   0.  ]]\n",
            "X_test [[334.   116.     4.     4.     3.5    9.54   1.  ]\n",
            " [314.   108.     4.     4.5    4.     9.04   1.  ]\n",
            " [315.   105.     2.     2.     2.5    7.65   0.  ]\n",
            " [312.   109.     3.     3.     3.     8.69   0.  ]\n",
            " [326.   112.     3.     3.5    3.     9.05   1.  ]\n",
            " [329.   111.     4.     4.5    4.     9.23   1.  ]\n",
            " [290.   100.     1.     1.5    2.     7.56   0.  ]\n",
            " [301.   106.     4.     2.5    3.     8.47   0.  ]\n",
            " [318.   109.     3.     3.5    4.     9.22   1.  ]\n",
            " [320.   112.     4.     3.     4.5    8.86   1.  ]\n",
            " [323.   108.     3.     3.5    3.     8.6    0.  ]\n",
            " [316.   109.     3.     3.5    3.     8.76   0.  ]\n",
            " [322.   103.     4.     3.     2.5    8.02   1.  ]\n",
            " [340.   115.     5.     4.5    4.5    9.45   1.  ]\n",
            " [324.   110.     3.     3.5    3.     9.22   1.  ]\n",
            " [296.    97.     2.     1.5    2.     7.8    0.  ]\n",
            " [332.   108.     5.     4.5    4.     9.02   1.  ]\n",
            " [300.    97.     2.     3.     3.     8.1    1.  ]\n",
            " [298.   101.     2.     1.5    2.     7.86   0.  ]\n",
            " [297.   101.     3.     2.     4.     7.67   1.  ]\n",
            " [307.   105.     2.     2.5    4.5    8.12   1.  ]\n",
            " [297.    99.     4.     3.     3.5    7.81   0.  ]\n",
            " [311.   102.     3.     4.5    4.     8.64   1.  ]\n",
            " [327.   109.     3.     3.5    4.     8.77   1.  ]\n",
            " [327.   112.     3.     3.     3.     8.72   1.  ]\n",
            " [301.   102.     3.     2.5    2.     8.13   1.  ]\n",
            " [330.   120.     5.     4.5    5.     9.56   1.  ]\n",
            " [328.   110.     4.     5.     4.     9.14   1.  ]\n",
            " [312.   105.     2.     2.5    3.     8.12   0.  ]\n",
            " [312.   107.     4.     4.5    4.     8.65   1.  ]\n",
            " [300.   101.     3.     3.5    2.5    7.88   0.  ]\n",
            " [319.   110.     3.     3.     2.5    8.79   0.  ]\n",
            " [305.   104.     2.     2.5    1.5    7.79   0.  ]\n",
            " [323.   113.     4.     4.     4.5    9.23   1.  ]\n",
            " [316.   104.     3.     3.     3.5    8.     1.  ]\n",
            " [319.   108.     3.     3.     3.5    8.54   1.  ]\n",
            " [300.    98.     1.     2.     2.5    8.02   0.  ]\n",
            " [332.   118.     5.     5.     5.     9.64   1.  ]\n",
            " [301.   104.     3.     3.5    4.     8.12   1.  ]\n",
            " [315.   107.     2.     4.     3.     8.5    1.  ]\n",
            " [340.   113.     4.     5.     5.     9.74   1.  ]\n",
            " [301.    97.     2.     3.     3.     7.88   1.  ]\n",
            " [311.   101.     2.     2.5    3.5    8.34   1.  ]\n",
            " [327.   113.     4.     4.5    4.5    9.11   1.  ]\n",
            " [340.   114.     5.     4.     4.     9.6    1.  ]\n",
            " [301.    99.     2.     3.     2.     8.22   0.  ]\n",
            " [337.   118.     4.     4.5    4.5    9.65   1.  ]\n",
            " [327.   111.     4.     4.     4.5    9.     1.  ]\n",
            " [327.   106.     4.     4.     4.5    8.75   1.  ]\n",
            " [328.   116.     5.     5.     5.     9.5    1.  ]\n",
            " [321.   111.     5.     5.     5.     9.45   1.  ]\n",
            " [299.   100.     2.     3.     3.5    7.88   0.  ]\n",
            " [303.   105.     5.     5.     4.5    8.65   0.  ]\n",
            " [301.    96.     1.     3.     4.     7.56   0.  ]\n",
            " [336.   118.     5.     4.5    5.     9.53   1.  ]\n",
            " [320.   103.     3.     3.     3.     7.7    0.  ]\n",
            " [339.   116.     4.     4.     3.5    9.8    1.  ]\n",
            " [318.   110.     3.     4.     3.     8.8    0.  ]\n",
            " [298.   105.     3.     3.5    4.     8.54   0.  ]\n",
            " [296.    95.     2.     3.     2.     7.54   1.  ]\n",
            " [301.    99.     3.     2.5    2.     8.45   1.  ]\n",
            " [308.   103.     2.     2.5    4.     8.36   1.  ]\n",
            " [305.   102.     2.     2.     2.5    8.18   0.  ]\n",
            " [304.   103.     5.     5.     3.     7.92   0.  ]\n",
            " [294.    93.     1.     1.5    2.     7.36   0.  ]\n",
            " [307.   108.     2.     4.     3.5    7.7    0.  ]\n",
            " [324.   113.     4.     4.5    4.5    9.25   1.  ]\n",
            " [329.   114.     5.     4.     5.     9.3    1.  ]\n",
            " [310.   104.     3.     2.     3.5    8.37   0.  ]\n",
            " [318.   106.     3.     2.     3.     8.65   0.  ]\n",
            " [303.   100.     2.     3.     3.5    8.06   1.  ]\n",
            " [326.   110.     3.     3.5    3.5    8.76   1.  ]\n",
            " [320.   101.     2.     2.5    3.     8.62   0.  ]\n",
            " [307.   105.     2.     2.5    3.     7.65   0.  ]\n",
            " [300.    99.     1.     1.     2.5    8.01   0.  ]\n",
            " [313.   106.     2.     2.5    2.     8.43   0.  ]\n",
            " [327.   113.     4.     4.5    5.     9.14   0.  ]\n",
            " [328.   115.     4.     4.5    4.     9.16   1.  ]\n",
            " [305.   102.     2.     1.5    2.5    7.64   0.  ]\n",
            " [305.    96.     4.     3.     4.5    8.26   0.  ]\n",
            " [326.   108.     3.     3.     3.5    8.89   0.  ]\n",
            " [320.   110.     5.     5.     4.5    9.22   1.  ]\n",
            " [309.   105.     4.     3.5    2.     8.18   0.  ]\n",
            " [322.   110.     4.     4.     5.     9.13   1.  ]\n",
            " [323.   104.     3.     4.     4.     8.44   1.  ]\n",
            " [318.   106.     2.     4.     4.     7.92   1.  ]\n",
            " [300.   104.     3.     3.5    3.     8.16   0.  ]\n",
            " [321.   110.     4.     3.5    4.     8.35   1.  ]\n",
            " [311.   107.     4.     4.5    4.5    9.     1.  ]\n",
            " [308.   103.     2.     3.     3.5    8.49   0.  ]\n",
            " [319.   105.     3.     3.     3.5    8.67   1.  ]\n",
            " [327.   116.     4.     4.     4.5    9.48   1.  ]\n",
            " [338.   115.     5.     4.5    5.     9.23   1.  ]\n",
            " [315.   104.     3.     3.     2.5    8.33   0.  ]\n",
            " [320.   112.     2.     3.5    3.5    8.78   1.  ]\n",
            " [299.    94.     1.     1.     1.     7.34   0.  ]\n",
            " [315.   106.     3.     4.5    3.5    8.42   0.  ]\n",
            " [329.   114.     2.     2.     4.     8.56   1.  ]\n",
            " [318.   110.     1.     2.5    3.5    8.54   1.  ]\n",
            " [314.   105.     3.     3.5    2.5    8.3    0.  ]]\n",
            "y_train [[0.77 0.71 0.62 0.72 0.75 0.64 0.66 0.82 0.73 0.71 0.71 0.94 0.83 0.94\n",
            "  0.45 0.8  0.71 0.86 0.45 0.53 0.76 0.9  0.75 0.79 0.74 0.64 0.52 0.97\n",
            "  0.85 0.43 0.74 0.72 0.87 0.54 0.84 0.46 0.86 0.97 0.65 0.71 0.61 0.64\n",
            "  0.79 0.36 0.93 0.72 0.95 0.76 0.71 0.71 0.9  0.56 0.88 0.66 0.62 0.68\n",
            "  0.8  0.84 0.52 0.48 0.61 0.79 0.69 0.54 0.61 0.64 0.76 0.68 0.73 0.93\n",
            "  0.58 0.65 0.65 0.47 0.59 0.85 0.79 0.71 0.8  0.67 0.64 0.78 0.62 0.78\n",
            "  0.71 0.9  0.86 0.57 0.79 0.64 0.62 0.38 0.63 0.49 0.68 0.8  0.81 0.34\n",
            "  0.86 0.57 0.78 0.92 0.81 0.78 0.68 0.72 0.71 0.74 0.71 0.7  0.74 0.71\n",
            "  0.76 0.71 0.79 0.59 0.95 0.61 0.63 0.91 0.82 0.58 0.64 0.73 0.78 0.77\n",
            "  0.63 0.66 0.92 0.42 0.69 0.74 0.58 0.75 0.85 0.47 0.81 0.61 0.93 0.82\n",
            "  0.77 0.72 0.79 0.52 0.78 0.57 0.96 0.52 0.66 0.64 0.86 0.76 0.67 0.7\n",
            "  0.86 0.65 0.75 0.84 0.83 0.84 0.89 0.61 0.51 0.48 0.97 0.59 0.92 0.86\n",
            "  0.58 0.57 0.75 0.97 0.72 0.74 0.9  0.73 0.46 0.82 0.94 0.64 0.65 0.71\n",
            "  0.6  0.74 0.92 0.42 0.79 0.92 0.34 0.56 0.73 0.61 0.84 0.75 0.62 0.73\n",
            "  0.8  0.86 0.79 0.78 0.73 0.64 0.84 0.81 0.76 0.73 0.77 0.69 0.66 0.94\n",
            "  0.62 0.67 0.78 0.91 0.78 0.93 0.56 0.91 0.72 0.81 0.79 0.93 0.91 0.77\n",
            "  0.55 0.8  0.76 0.7  0.84 0.62 0.52 0.78 0.88 0.46 0.68 0.92 0.67 0.58\n",
            "  0.75 0.42 0.56 0.6  0.73 0.56 0.72 0.49 0.73 0.77 0.63 0.81 0.85 0.59\n",
            "  0.65 0.76 0.8  0.71 0.63 0.95 0.96 0.89 0.9  0.56 0.93 0.47 0.89 0.91\n",
            "  0.73 0.69 0.73 0.93 0.44 0.91 0.73 0.87 0.82 0.67 0.92 0.8  0.54 0.82\n",
            "  0.84 0.62 0.5  0.63 0.57 0.52 0.62 0.61 0.7  0.46 0.71 0.81 0.91 0.91\n",
            "  0.67 0.64 0.74 0.94 0.85 0.66 0.95 0.68 0.37 0.7  0.76 0.68 0.73 0.74\n",
            "  0.77 0.72 0.53 0.87 0.85 0.66 0.9  0.7  0.9  0.69 0.72 0.76 0.76 0.79\n",
            "  0.83 0.78 0.58 0.5  0.57 0.94 0.7  0.71 0.74 0.38 0.81 0.67 0.78 0.49\n",
            "  0.75 0.65 0.62 0.65 0.64 0.53 0.52 0.65 0.8  0.53 0.89 0.79 0.8  0.8\n",
            "  0.76 0.7  0.69 0.76 0.51 0.87 0.91 0.88 0.96 0.93 0.65 0.36 0.82 0.47\n",
            "  0.88 0.71 0.7  0.67 0.89 0.57 0.89 0.87 0.87 0.96 0.64 0.49 0.59 0.78\n",
            "  0.69 0.79 0.96 0.94 0.81 0.79 0.95 0.66 0.69 0.8  0.94 0.71 0.94 0.84\n",
            "  0.64 0.93 0.96 0.87 0.72 0.57 0.55 0.62]]\n",
            "y_test [[0.93 0.84 0.39 0.77 0.74 0.89 0.47 0.57 0.68 0.82 0.45 0.77 0.61 0.94\n",
            "  0.89 0.49 0.87 0.65 0.54 0.57 0.67 0.54 0.68 0.79 0.74 0.68 0.93 0.82\n",
            "  0.64 0.73 0.59 0.72 0.53 0.89 0.72 0.71 0.61 0.94 0.68 0.56 0.96 0.44\n",
            "  0.7  0.89 0.9  0.64 0.92 0.84 0.76 0.94 0.93 0.68 0.77 0.54 0.94 0.64\n",
            "  0.96 0.63 0.69 0.44 0.68 0.7  0.62 0.71 0.46 0.48 0.89 0.86 0.7  0.71\n",
            "  0.64 0.79 0.7  0.58 0.58 0.62 0.83 0.78 0.59 0.54 0.8  0.92 0.65 0.86\n",
            "  0.73 0.64 0.71 0.72 0.78 0.66 0.73 0.9  0.91 0.67 0.73 0.42 0.72 0.72\n",
            "  0.67 0.54]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oIRCGvYt0az"
      },
      "source": [
        "###  5) Feature scaling\n",
        "####  Feature scaling is a method used to standardize the range of independent variables or features of data. In data processing, it is also known as data normalization and is generally performed during the data preprocessing step. https://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html. \n",
        "#### <b>Question: </b>Is it useful or not to normalize your features? If so, normalize your data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2Tj0y01t0a0"
      },
      "source": [
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train,y_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRllrtkot0a3"
      },
      "source": [
        "### 6) Make your first Simple Neural Network also known as Perceptron\n",
        "The Network is initialized, since we want to construct a very simple Network: following this link https://keras.io/. We will construct hidden layer(In this case 2 hidden layers are sufficients). For documentation about creating  a sequential model please see the tutorial in this link  Compile the model using: model.compile()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naX8sLIDt0a4"
      },
      "source": [
        "# Import Librairies\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGexyTYot0a7"
      },
      "source": [
        "# 9-Building a model\n",
        "def build_model():\n",
        "  model = keras.Sequential([\n",
        "    layers.Dense(14, activation= 'relu', input_dim=7),\n",
        "    layers.Dense(14, activation= 'sigmoid'),\n",
        "    tf.keras.layers.Softmax(axis=-1)\n",
        "  ])\n",
        "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "  model.compile(loss='mean_squared_error',\n",
        "                optimizer='adam',\n",
        "                metrics=['accuracy', 'mse'])\n",
        "  return model\n",
        "\n",
        "\n",
        "model1 = build_model()\n",
        "#Initialization of Network\n",
        "\n",
        "#defining layers\n",
        "# First layer\n",
        "# Second layer\n",
        "# Compile the model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYvRTgPYt0a9"
      },
      "source": [
        "### 7) Fit your trained model\n",
        "A model that is well-fitted produces more accurate outcomes, a model that is overfitted matches the train data too closely (low train loss, but high test loss), and a model that is underfitted doesn’t match the train data closely enough (high train loss).\n",
        "\n",
        "a) An epoch is an iteration over the entire x and y data provided\n",
        "\n",
        "b) Batch size = Number of samples per gradient update. The higher the batch size, the more memory space you'll need.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1WntMTCt0a-",
        "outputId": "530a5efc-0e0f-41c2-9bb7-058f29a52a0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "batch_size = 50\n",
        "epochs = 30\n",
        "fitting = model1.fit(X_train,y_train,validation_data=(X_test,y_test), batch_size=batch_size,epochs=epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.4459 - accuracy: 0.0000e+00 - mse: 0.4459 - val_loss: 0.4309 - val_accuracy: 0.0000e+00 - val_mse: 0.4309\n",
            "Epoch 2/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4459 - accuracy: 0.0000e+00 - mse: 0.4459 - val_loss: 0.4308 - val_accuracy: 0.0000e+00 - val_mse: 0.4308\n",
            "Epoch 3/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.0000e+00 - mse: 0.4458 - val_loss: 0.4308 - val_accuracy: 0.0000e+00 - val_mse: 0.4308\n",
            "Epoch 4/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.0000e+00 - mse: 0.4458 - val_loss: 0.4308 - val_accuracy: 0.0000e+00 - val_mse: 0.4308\n",
            "Epoch 5/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.0000e+00 - mse: 0.4458 - val_loss: 0.4308 - val_accuracy: 0.0000e+00 - val_mse: 0.4308\n",
            "Epoch 6/30\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.0000e+00 - mse: 0.4458 - val_loss: 0.4308 - val_accuracy: 0.0000e+00 - val_mse: 0.4308\n",
            "Epoch 7/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.0000e+00 - mse: 0.4458 - val_loss: 0.4308 - val_accuracy: 0.0000e+00 - val_mse: 0.4308\n",
            "Epoch 8/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.0000e+00 - mse: 0.4458 - val_loss: 0.4308 - val_accuracy: 0.0000e+00 - val_mse: 0.4308\n",
            "Epoch 9/30\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.0000e+00 - mse: 0.4458 - val_loss: 0.4308 - val_accuracy: 0.0000e+00 - val_mse: 0.4308\n",
            "Epoch 10/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.0000e+00 - mse: 0.4458 - val_loss: 0.4308 - val_accuracy: 0.0000e+00 - val_mse: 0.4308\n",
            "Epoch 11/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.0000e+00 - mse: 0.4458 - val_loss: 0.4308 - val_accuracy: 0.0000e+00 - val_mse: 0.4308\n",
            "Epoch 12/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.0000e+00 - mse: 0.4458 - val_loss: 0.4308 - val_accuracy: 0.0000e+00 - val_mse: 0.4308\n",
            "Epoch 13/30\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.0000e+00 - mse: 0.4458 - val_loss: 0.4308 - val_accuracy: 0.0000e+00 - val_mse: 0.4308\n",
            "Epoch 14/30\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.0000e+00 - mse: 0.4458 - val_loss: 0.4308 - val_accuracy: 0.0000e+00 - val_mse: 0.4308\n",
            "Epoch 15/30\n",
            "8/8 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.0000e+00 - mse: 0.4458 - val_loss: 0.4308 - val_accuracy: 0.0000e+00 - val_mse: 0.4308\n",
            "Epoch 16/30\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.0000e+00 - mse: 0.4458 - val_loss: 0.4308 - val_accuracy: 0.0000e+00 - val_mse: 0.4308\n",
            "Epoch 17/30\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.0000e+00 - mse: 0.4458 - val_loss: 0.4308 - val_accuracy: 0.0000e+00 - val_mse: 0.4308\n",
            "Epoch 18/30\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.0000e+00 - mse: 0.4458 - val_loss: 0.4308 - val_accuracy: 0.0000e+00 - val_mse: 0.4308\n",
            "Epoch 19/30\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.0000e+00 - mse: 0.4458 - val_loss: 0.4308 - val_accuracy: 0.0000e+00 - val_mse: 0.4308\n",
            "Epoch 20/30\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4458 - accuracy: 0.0000e+00 - mse: 0.4458 - val_loss: 0.4308 - val_accuracy: 0.0000e+00 - val_mse: 0.4308\n",
            "Epoch 21/30\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 0.4458 - accuracy: 0.0000e+00 - mse: 0.4458 - val_loss: 0.4308 - val_accuracy: 0.0000e+00 - val_mse: 0.4308\n",
            "Epoch 22/30\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.0000e+00 - mse: 0.4458 - val_loss: 0.4308 - val_accuracy: 0.0000e+00 - val_mse: 0.4308\n",
            "Epoch 23/30\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.0000e+00 - mse: 0.4458 - val_loss: 0.4308 - val_accuracy: 0.0000e+00 - val_mse: 0.4308\n",
            "Epoch 24/30\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.0000e+00 - mse: 0.4458 - val_loss: 0.4308 - val_accuracy: 0.0000e+00 - val_mse: 0.4308\n",
            "Epoch 25/30\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.0000e+00 - mse: 0.4458 - val_loss: 0.4308 - val_accuracy: 0.0000e+00 - val_mse: 0.4308\n",
            "Epoch 26/30\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.0000e+00 - mse: 0.4458 - val_loss: 0.4308 - val_accuracy: 0.0000e+00 - val_mse: 0.4308\n",
            "Epoch 27/30\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.0000e+00 - mse: 0.4458 - val_loss: 0.4308 - val_accuracy: 0.0000e+00 - val_mse: 0.4308\n",
            "Epoch 28/30\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.0000e+00 - mse: 0.4458 - val_loss: 0.4308 - val_accuracy: 0.0000e+00 - val_mse: 0.4308\n",
            "Epoch 29/30\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.0000e+00 - mse: 0.4458 - val_loss: 0.4308 - val_accuracy: 0.0000e+00 - val_mse: 0.4308\n",
            "Epoch 30/30\n",
            "8/8 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.0000e+00 - mse: 0.4458 - val_loss: 0.4308 - val_accuracy: 0.0000e+00 - val_mse: 0.4308\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgtwxGf9eKAH"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P02_1eGLeJDs",
        "outputId": "d6ffcd54-c688-43f1-f51a-77591c716981",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "%matplotlib inline\n",
        "plt.plot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9vIC7HL4uMA"
      },
      "source": [
        "### 8) Make a prediction for test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upK4NS34t0bD",
        "outputId": "47da5af4-4f77-4d9c-f0c3-43c19621adea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "x = np.array([220,100,2,3.5,3,8,0],dtype = 'float32')\n",
        "print(x)\n",
        "x = x.reshape(-1, 7)\n",
        "x = scaler.transform(x)\n",
        "model1.predict(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[220.  100.    2.    3.5   3.    8.    0. ]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.05432913, 0.10702512, 0.05286033, 0.10193793, 0.05933245,\n",
              "        0.06749596, 0.09837451, 0.06431349, 0.06093952, 0.05673836,\n",
              "        0.05795191, 0.06251211, 0.10713977, 0.04904939]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hanNpjqqt0bG"
      },
      "source": [
        "### 9)Predict new student:\n",
        "The student with the following informations will be admitted:\n",
        "\n",
        "GRE Score: 220,   TOEFL Score: 100, University rating: 2,  SOP: 3.5, LOR: 3, CGPA: 8, Research: 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdWBhS4Ht0bG",
        "outputId": "fcb6c472-fc16-4a52-d8ac-6dc1373dba10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "#model1.predict(220)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-021964cf7da0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m220\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    129\u001b[0m           method.__name__))\n\u001b[0;32m--> 130\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m   return tf_decorator.make_decorator(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1577\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1578\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1579\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_x_y_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m       \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Data cardinality is ambiguous:\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_x_y_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m       \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Data cardinality is ambiguous:\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    885\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v2_behavior\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 887\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OwWMHid03_m"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}